{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.linear_model import LassoCV\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "data = fetch_california_housing()\n",
        "feature_names = data.feature_names\n",
        "feature_names\n"
      ],
      "metadata": {
        "id": "JVUUFXqnFV2q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = data.data, data.target\n",
        "\n",
        "# only use first 10 samples for training\n",
        "num_sample = 10\n",
        "X, y = X[:num_sample], y[:num_sample]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "print('X_train.shape: ',X_train.shape)\n",
        "print('X_test.shape: ',X_test.shape)"
      ],
      "metadata": {
        "id": "eSBlBavSCwdX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# normalize the features\n",
        "def standardize(X_train, X_test):\n",
        "    \"\"\"\n",
        "    Standardize features by removing the mean and scaling to unit variance.\n",
        "\n",
        "    The standard score of a sample x is calculated as:\n",
        "        z = (x - mean) / std\n",
        "\n",
        "    where mean and std are computed from the training set.\n",
        "\n",
        "    Args:\n",
        "        X_train: Training data of shape (n_samples, n_features)\n",
        "        X_test: Test data of shape (m_samples, n_features)\n",
        "\n",
        "    Returns:\n",
        "        X_train_standardized: Standardized training data\n",
        "        X_test_standardized: Standardized test data (using training statistics)\n",
        "    \"\"\"\n",
        "    ...\n",
        "\n",
        "    return X_train_standardized, X_test_standardized\n",
        "\n",
        "X_train, X_test = standardize(X_train, X_test)\n"
      ],
      "metadata": {
        "id": "byvJRdrLV0ib"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "alphas = np.logspace(-3, 3, 50)\n",
        "\n",
        "lasso_cv = LassoCV(alphas=alphas, cv=5, random_state=42, max_iter=10000)\n",
        "lasso_cv.fit(..., ...)\n",
        "\n",
        "best_alpha = lasso_cv.alpha_\n",
        "y_pred = lasso_cv.predict(X_test)\n",
        "test_mse = mean_squared_error(y_test, y_pred)\n",
        "n_surviving_features = np.sum(lasso_cv.coef_ != 0)\n",
        "\n",
        "print(f\"Best α: {best_alpha:.6f}\")\n",
        "print(f\"Surviving features: {n_surviving_features}\")\n",
        "print(f\"Test MSE: {test_mse:.4f}\")\n",
        "print(\"Surviving feature names:\", [f for f, c in zip(feature_names, lasso_cv.coef_) if c != 0])\n",
        "\n",
        "# Plot regularization path and MSE analysis\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Regularization Path Analysis\")\n",
        "print(\"=\"*60)\n"
      ],
      "metadata": {
        "id": "HDmrIpKVW6ma"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Calculate coefficients and errors for each alpha\n",
        "coef_path = []\n",
        "train_errors = []\n",
        "for alpha in alphas:\n",
        "    lasso = Lasso(alpha=alpha, max_iter=10000, random_state=42)\n",
        "    lasso.fit(X_train, y_train)\n",
        "    coef_path.append(lasso.coef_)\n",
        "    y_train_pred = lasso.predict(X_train)\n",
        "    train_errors.append(mean_squared_error(y_train, y_train_pred))\n",
        "\n",
        "coef_path = np.array(coef_path)  # shape: (n_alphas, n_features)\n",
        "\n",
        "# Get cross-validation results\n",
        "# LassoCV stores the alphas it actually used\n",
        "cv_alphas = lasso_cv.alphas_\n",
        "mse_path = lasso_cv.mse_path_  # shape: (n_alphas, n_folds)\n",
        "mean_mse = np.mean(mse_path, axis=1)\n",
        "std_mse = np.std(mse_path, axis=1)\n",
        "\n"
      ],
      "metadata": {
        "id": "JxkTsJV8W91H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "YqearCQ9XGvC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ========== Plot 1: MSE vs Alpha ==========\n",
        "fig2, ax2 = plt.subplots(figsize=(10, 6))\n",
        "\n",
        "# Plot training error (using our alphas)\n",
        "ax2.plot(alphas, train_errors, 'b-', linewidth=2.5, label='Training MSE', alpha=0.8)\n",
        "\n",
        "# Plot validation error with confidence interval (using CV alphas)\n",
        "ax2.plot(cv_alphas, mean_mse, 'r-', linewidth=2.5, label='Validation MSE (5-Fold CV)', alpha=0.8)\n",
        "\n",
        "# Mark the best alpha - find the minimum validation MSE\n",
        "best_idx = np.argmin(mean_mse)\n",
        "best_val_mse = mean_mse[best_idx]\n",
        "ax2.axvline(x=best_alpha, color='green', linestyle='--', linewidth=2,\n",
        "            label=f'Best α = {best_alpha:.4f}')\n",
        "ax2.plot(best_alpha, best_val_mse, 'go', markersize=10,\n",
        "         label=f'Min Val MSE = {best_val_mse:.4f}', zorder=5)\n",
        "\n",
        "# Formatting\n",
        "ax2.set_xscale('log')\n",
        "ax2.set_xlabel('λ', fontsize=14, fontweight='bold')\n",
        "ax2.set_ylabel('Mean Squared Error', fontsize=12, fontweight='bold')\n",
        "ax2.set_title('MSE vs. α', fontsize=16, fontweight='bold', pad=15)\n",
        "ax2.legend(loc='best', fontsize=9, framealpha=0.9)\n",
        "ax2.grid(True, alpha=0.3, linestyle='--')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "print(f\"\\nFeature names: {feature_names}\")\n",
        "print(f\"\\nInterpretation:\")\n",
        "print(f\"- At optimal α = {best_alpha:.4f}, {n_surviving_features} features survive\")\n",
        "print(f\"- This balances model complexity and generalization performance\")\n",
        "print(f\"- Using K=5 folds for cross-validation with small dataset (n={len(X_train)})\")"
      ],
      "metadata": {
        "id": "yPqed4sMXIGQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ========== Plot 2: Regularization Path ==========\n",
        "fig1, ax1 = plt.subplots(figsize=(10, 6))\n",
        "colors = plt.cm.tab10(np.linspace(0, 1, len(feature_names)))\n",
        "for i, (feature_name, color) in enumerate(zip(feature_names, colors)):\n",
        "    ax1.plot(alphas, coef_path[:, i], linewidth=2.5, label=feature_name, color=color)\n",
        "\n",
        "# Mark the best alpha with vertical line\n",
        "ax1.axvline(x=best_alpha, color='black', linestyle='--', linewidth=2,\n",
        "            label=f'Best α = {best_alpha:.4f}')\n",
        "\n",
        "# Formatting\n",
        "ax1.set_xscale('log')\n",
        "ax1.set_xlabel('λ', fontsize=14, fontweight='bold')\n",
        "ax1.set_ylabel('Coefficient Value', fontsize=12, fontweight='bold')\n",
        "ax1.set_title('Regularization Path', fontsize=16, fontweight='bold', pad=15)\n",
        "ax1.axhline(y=0, color='black', linestyle='-', linewidth=0.8, alpha=0.3)\n",
        "ax1.legend(loc='best', fontsize=9, framealpha=0.9)\n",
        "ax1.grid(True, alpha=0.2, linestyle='--')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "print(f\"\\nFeature names: {feature_names}\")\n",
        "print(f\"\\nInterpretation:\")\n",
        "print(f\"- At optimal α = {best_alpha:.4f}, {n_surviving_features} features survive\")\n",
        "print(f\"- This balances model complexity and generalization performance\")\n",
        "print(f\"- Using K=5 folds for cross-validation with small dataset (n={len(X_train)})\")\n"
      ],
      "metadata": {
        "id": "dkqpSL3iXRyf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}